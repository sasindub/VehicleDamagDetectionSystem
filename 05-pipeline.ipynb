{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import h5py\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "from IPython.display import Image, display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = VGG16(weights = 'imagenet')\n",
    "model2 = load_model('data2/ft_model.h5')\n",
    "model3 = load_model('data3/ft_model.h5')\n",
    "model4 = load_model('data4/ft_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vgg16_cat_list.pk', 'rb') as f:\n",
    "    cat_list = pk.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipe 1: check for car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_INDEX = None\n",
    "\n",
    "def get_predictions(preds, top=5):\n",
    "    global CLASS_INDEX\n",
    "    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n",
    "        raise ValueError('`decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: ' + str(preds.shape))\n",
    "    if CLASS_INDEX is None:\n",
    "        fpath = get_file('imagenet_class_index.json',CLASS_INDEX_PATH,cache_subdir='models')\n",
    "        CLASS_INDEX = json.load(open(fpath))\n",
    "    results = []\n",
    "    for pred in preds:\n",
    "        top_indices = pred.argsort()[-top:][::-1]\n",
    "        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n",
    "        result.sort(key=lambda x: x[2], reverse=True)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_224(img_path):\n",
    "    urllib.request.urlretrieve(img_path, 'save.jpg') # or other way to upload image\n",
    "    img = load_img('save.jpg', target_size=(224, 224))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe1(img_224, model):\n",
    "    print(\"Ensuring entered picture is a car...\")\n",
    "    out = model.predict(img_224)\n",
    "    preds = get_predictions(out, top=5)\n",
    "    for pred in preds[0]:\n",
    "        if pred[0:2] in cat_list:\n",
    "            return True #\"Successful. Proceeding to damage assessment...\"\n",
    "    return False #\"The entered image is a not a car. Please try again. Consider a different angle or lighting.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipe 2: checking for damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img_256(img_path):\n",
    "    urllib.request.urlretrieve(img_path, 'save.jpg')\n",
    "    img = load_img('save.jpg', target_size=(256, 256))\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)/255\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe2(img_256, model):\n",
    "    print(\"Validating that damage exists....\")\n",
    "    pred = model.predict(img_256)\n",
    "    if(pred[0][0]<=0.5):\n",
    "        return True #print(\"Validation complete - proceed to location and severity determination\")\n",
    "    else:\n",
    "        return False\n",
    "        #print (\"Are you sure that your car is damaged? Please submit another picture of the damage.\")\n",
    "        #print (\"Hint: Try zooming in/out, using a different angle or different lighting\")      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipe 3: location and severity assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe3_loc(img_256, model):\n",
    "    print(\"Determining location of damage...\")\n",
    "    pred = model.predict(img_256)\n",
    "    pred_labels = np.argmax(pred, axis=1)\n",
    "    d = {0:'front', 1:'rear', 2:'side'}\n",
    "    for key in d.keys():\n",
    "        if pred_labels[0] == key:\n",
    "            print(\"Result: damage to {} of vehicle\".format(d[key]))\n",
    "    print(\"Location assessment complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe3_sev(img_256, model):\n",
    "    print(\"Determining severity of damage...\")\n",
    "    pred = model.predict(img_256)\n",
    "    pred_labels = np.argmax(pred, axis=1)\n",
    "    d = {0:'minor', 1:'moderate', 2:'severe'}\n",
    "    for key in d.keys():\n",
    "        if pred_labels[0] == key:\n",
    "            print(\"Result:{} damage\".format(d[key]))\n",
    "    print(\"Severity assessment complete.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img_path): \n",
    "    while True:\n",
    "        #print(\"Submit image link (or type 'exit' to quit)\") \n",
    "        #img_path = input(\"Upload Image File Here:\") \n",
    "        #if img_path == 'exit': \n",
    "        #    return None \n",
    "        #clear_output()   \n",
    "        img_224 = prepare_image_224(img_path) \n",
    "        p1 = pipe1(img_224, model1) \n",
    "        display(Image('save.jpg', width=300))  \n",
    "        if p1 is False:\n",
    "            print(\"The entered image is a not a car. Please try again. Consider a different angle or lighting.\") \n",
    "            break \n",
    "        else: \n",
    "            print(\"Successful. Proceeding to damage assessment...\") \n",
    "\n",
    "        img_256 = prepare_img_256(img_path) \n",
    "        p2 = pipe2(img_256, model2) \n",
    "        \n",
    "        if p2 is False: \n",
    "            print (\"Are you sure that your car is damaged? Please submit another picture of the damage.\") \n",
    "            print (\"Hint: Try zooming in/out, using a different angle or different lighting\")       \n",
    "            break \n",
    "        else: \n",
    "            print(\"Validation complete - proceed to location and severity determination\") \n",
    "\n",
    "        x = pipe3_loc(img_256, model3) \n",
    "        y = pipe3_sev(img_256, model4) \n",
    "        break "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
